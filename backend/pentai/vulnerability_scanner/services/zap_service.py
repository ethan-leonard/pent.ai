import logging
import time
from zapv2 import ZAPv2
from vulnerability_scanner.models import Vulnerability

logger = logging.getLogger(__name__)

class ZAPService:
    """Service for verifying connection to OWASP ZAP and performing scans"""
    
    def __init__(self):
        """Initialize the ZAP service with connection to ZAP API"""
        self.apiKey = None
        # Use localhost since startup.sh maps ZAP to port 8090 on localhost
        self.zap = ZAPv2(
            apikey=self.apiKey, 
            proxies={'http': 'http://localhost:8090', 'https': 'http://localhost:8090'},
        )
        
    def verify_connection(self, url):
        """
        Verify that we can connect to ZAP and access a URL.
        (Existing connection test)
        """
        try:
            logger.info("Attempting to connect to ZAP API")
            version = self.zap.core.version
            logger.info(f"Connected to ZAP version: {version}")
            return {
                "zap_connected": True,
                "zap_version": version,
                "success": True,
                "message": f"Connected to ZAP (version {version})"
            }
        except Exception as e:
            logger.error(f"Error connecting to ZAP: {str(e)}")
            return {
                "zap_connected": False,
                "success": False,
                "error": str(e),
                "message": f"Failed to connect to ZAP: {str(e)}"
            }
    
    def spider_scan(self, url):
        """
        Perform both traditional and Ajax spider scans on the target URL 
        and return combined results.
        """
        try:
            logger.info(f"Opening target URL: {url}")
            self.zap.urlopen(url)
            time.sleep(2)
            
            # Start traditional spider scan
            logger.info(f"Starting traditional spider scan on {url}")
            spider_id = self.zap.spider.scan(url)
            while True:
                status_str = self.zap.spider.status(spider_id)
                try:
                    percent = int(status_str)
                except ValueError:
                    logger.error(f"Unexpected spider status: {status_str}")
                    break
                logger.info(f"Traditional spider scan progress: {percent}%")
                if percent >= 100:
                    break
                time.sleep(1)
            
            # Get traditional spider results
            try:
                spider_results = self.zap.spider.results(spider_id)
                logger.info(f"Traditional spider scan completed. Found {len(spider_results)} URLs.")
            except Exception as e:
                logger.error(f"Error getting spider results: {str(e)}")
                spider_results = []
            
            # Start Ajax spider scan for better JavaScript coverage
            ajax_urls = []
            try:
                logger.info(f"Starting Ajax spider scan on {url}")
                # Ensure ZAP is responsive before starting Ajax spider
                self.zap.core.version
                
                # Start the Ajax spider
                self.zap.ajaxSpider.scan(url)
                
                # Set timeout for Ajax spider (5 minutes)
                ajax_timeout = time.time() + 300
                
                # Monitor Ajax spider status
                while self.zap.ajaxSpider.status == 'running':
                    if time.time() > ajax_timeout:
                        logger.warning("Ajax spider timed out after 5 minutes, stopping.")
                        try:
                            self.zap.ajaxSpider.stop()
                        except Exception as e:
                            logger.error(f"Error stopping Ajax spider: {str(e)}")
                        break
                    logger.info(f"Ajax spider status: {self.zap.ajaxSpider.status}")
                    time.sleep(5)
                
                # Make sure to wait a moment for the Ajax spider to fully finish
                time.sleep(2)
                
                # Get Ajax spider results (all of them) - with error handling
                try:
                    # Verify ZAP is still responsive
                    self.zap.core.version
                    
                    ajax_results = self.zap.ajaxSpider.results(start=0, count=1000)
                    ajax_urls = [item.get('url', '') for item in ajax_results if isinstance(item, dict) and 'url' in item]
                    logger.info(f"Ajax spider completed. Found {len(ajax_urls)} URLs.")
                except Exception as e:
                    logger.error(f"Error retrieving Ajax spider results: {str(e)}")
                    ajax_urls = []
            except Exception as e:
                logger.error(f"Error during Ajax spider scan: {str(e)}")
                # Continue with traditional spider results only
            
            # Make sure ZAP is still responsive after Ajax spider
            try:
                self.zap.core.version
                logger.info("ZAP API is still responsive after Ajax Spider")
            except Exception as e:
                logger.error(f"ZAP API became unresponsive: {str(e)}")
                # Try to reconnect
                try:
                    self.zap = ZAPv2(
                        apikey=self.apiKey, 
                        proxies={'http': 'http://localhost:8090', 'https': 'http://localhost:8090'},
                    )
                    logger.info("Successfully reconnected to ZAP API")
                except Exception as re:
                    logger.error(f"Failed to reconnect to ZAP: {str(re)}")
            
            # Combine results from both spiders - filter out any None or empty values
            combined_results = list(set(url for url in spider_results + ajax_urls if url))
            logger.info(f"Combined spider scans completed. Total unique URLs: {len(combined_results)}")
            
            return {
                "success": True,
                "message": "Traditional and Ajax spider scans completed.",
                "spider_results": combined_results
            }
        except Exception as e:
            logger.error(f"Error during spider scan: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "message": f"Spider scan failed: {str(e)}"
            }

    def active_scan_all(self, url):
        try:
             logger.info(f"Starting active scan (SQL Injection) on {url}")
             active_scan_id = self.zap.ascan.scan(url, recurse=True)
             start_time = time.time()
             timeout = 500  # seconds
             
             while True:
                 status_str = self.zap.ascan.status(active_scan_id)
                 if status_str == "does_not_exist":
                     logger.warning("Active scan status returned 'does_not_exist', treating as complete.")
                     break
                 try:
                     status_int = int(status_str)
                 except ValueError:
                     logger.error(f"Unexpected active scan status: {status_str}")
                     return {
                         "success": False,
                         "error": f"Unexpected scan status: {status_str}",
                         "message": f"Active scan failed with unexpected status: {status_str}"
                     }
                 logger.info(f"Active scan progress: {status_int}%")
                 if status_int >= 100:
                     break
                 if time.time() - start_time > timeout:
                     logger.error("Active scan timed out")
                     return {
                         "success": False,
                         "error": "Timeout",
                         "message": f"Active scan timed out after {timeout} seconds"
                     }
                 time.sleep(5)
             
             logger.info("Active scan completed.")
             time.sleep(2)
             
             # Retrieve all alerts for the target URL
             all_alerts = self.zap.alert.alerts(baseurl=url)
             logger.info(f"Total alerts found: {len(all_alerts)}")
             
             # Log every alert for debugging
             for alert in all_alerts:
                 logger.info(f"Alert retrieved: {alert}")
             
             # Get detected alerts
             dectected_alerts = [
                 alert for alert in all_alerts 
             ]
             logger.info(f"Found {len(dectected_alerts)} SQL Injection alerts.")
             
             # Save vulnerabilities to the database
             for alert in dectected_alerts:
                 Vulnerability.objects.create(
                     name=alert.get('alert'),
                     description=alert.get('attack', '') or alert.get('description', ''),
                     url=alert.get('url', url),
                     risk=alert.get('risk', 'Unknown'),
                     confidence=alert.get('confidence', 'Unknown'),
                     alert_id=alert.get('alertId', '')
                 )
             return {
                 "success": True,
                 "message": f"Active scan completed. Found {len(dectected_alerts)} SQL Injection vulnerabilities.",
                 "alerts": dectected_alerts
             }
        except Exception as e:
             logger.error(f"Error during active scan: {str(e)}")
             return {
                 "success": False,
                 "error": str(e),
                 "message": f"Active scan failed: {str(e)}"
             }